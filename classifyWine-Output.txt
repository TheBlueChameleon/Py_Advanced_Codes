2021-05-22 12:00:50.450052: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-05-22 12:00:50.450095: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-05-22 12:00:52.041673: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-22 12:00:52.041835: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-05-22 12:00:52.041853: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-05-22 12:00:52.041879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (blue-chameleon-HP-250-G7-Notebook-PC): /proc/driver/nvidia/version does not exist
2021-05-22 12:00:52.042063: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-22 12:00:52.042210: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set

################################################################################
SOURCE DATA SUMMARY:

White Wines:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 4898 entries, 0 to 4897
Data columns (total 13 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         4898 non-null   float64
 1   volatile acidity      4898 non-null   float64
 2   citric acid           4898 non-null   float64
 3   residual sugar        4898 non-null   float64
 4   chlorides             4898 non-null   float64
 5   free sulfur dioxide   4898 non-null   float64
 6   total sulfur dioxide  4898 non-null   float64
 7   density               4898 non-null   float64
 8   pH                    4898 non-null   float64
 9   sulphates             4898 non-null   float64
 10  alcohol               4898 non-null   float64
 11  quality               4898 non-null   int64  
 12  type                  4898 non-null   int64  
dtypes: float64(11), int64(2)
memory usage: 497.6 KB

Red Wines:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1599 entries, 0 to 1598
Data columns (total 13 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         1599 non-null   float64
 1   volatile acidity      1599 non-null   float64
 2   citric acid           1599 non-null   float64
 3   residual sugar        1599 non-null   float64
 4   chlorides             1599 non-null   float64
 5   free sulfur dioxide   1599 non-null   float64
 6   total sulfur dioxide  1599 non-null   float64
 7   density               1599 non-null   float64
 8   pH                    1599 non-null   float64
 9   sulphates             1599 non-null   float64
 10  alcohol               1599 non-null   float64
 11  quality               1599 non-null   int64  
 12  type                  1599 non-null   int64  
dtypes: float64(11), int64(2)
memory usage: 162.5 KB

All Wines:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 13 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         6497 non-null   float64
 1   volatile acidity      6497 non-null   float64
 2   citric acid           6497 non-null   float64
 3   residual sugar        6497 non-null   float64
 4   chlorides             6497 non-null   float64
 5   free sulfur dioxide   6497 non-null   float64
 6   total sulfur dioxide  6497 non-null   float64
 7   density               6497 non-null   float64
 8   pH                    6497 non-null   float64
 9   sulphates             6497 non-null   float64
 10  alcohol               6497 non-null   float64
 11  quality               6497 non-null   int64  
 12  type                  6497 non-null   int64  
dtypes: float64(11), int64(2)
memory usage: 660.0 KB

################################################################################
TRAINING DATA ANALYSIS

Training Input Data:
      fixed acidity  volatile acidity  citric acid  ...    pH  sulphates  alcohol
1700            7.1              0.12         0.32  ...  3.40       0.41      9.4
5199            6.8              0.12         0.30  ...  3.20       0.35      9.9
3340            7.7              0.38         0.40  ...  3.18       0.32     12.9
86              8.6              0.49         0.28  ...  2.93       1.95      9.9
5587            6.1              0.20         0.17  ...  3.30       0.43     11.4
...             ...               ...          ...  ...   ...        ...      ...
3772            7.6              0.32         0.58  ...  3.15       0.54      9.2
5191            5.6              0.28         0.27  ...  3.35       0.44     10.7
5226            6.4              0.37         0.20  ...  3.24       0.43      9.5
5390            6.5              0.26         0.50  ...  3.18       0.47      9.5
860             7.2              0.62         0.06  ...  3.51       0.54      9.5

[4352 rows x 11 columns]
<class 'pandas.core.frame.DataFrame'>
Int64Index: 4352 entries, 1700 to 860
Data columns (total 11 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         4352 non-null   float64
 1   volatile acidity      4352 non-null   float64
 2   citric acid           4352 non-null   float64
 3   residual sugar        4352 non-null   float64
 4   chlorides             4352 non-null   float64
 5   free sulfur dioxide   4352 non-null   float64
 6   total sulfur dioxide  4352 non-null   float64
 7   density               4352 non-null   float64
 8   pH                    4352 non-null   float64
 9   sulphates             4352 non-null   float64
 10  alcohol               4352 non-null   float64
dtypes: float64(11)
memory usage: 408.0 KB
<class 'pandas.core.frame.DataFrame'>

Training Output Data:
[0 0 0 ... 0 0 1]
(4352,)

################################################################################
KERAS DEBUG OUTPUT


################################################################################
MODEL DESCRIPTION

Shape: (None, 1) 

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 12)                144       
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 104       
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 9         
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________

Configuration: {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 11), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'dense_input'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'batch_input_shape': (None, 11), 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]} 

Weights:
 [array([[-0.41395798,  0.44327974,  0.3561291 ,  0.48590708, -0.00516319,
        -0.40618458, -0.30743405,  0.02283126,  0.03958154,  0.40750825,
        -0.3525419 , -0.19480342],
       [-0.41650707, -0.27888966, -0.12512016, -0.1334089 , -0.45189533,
         0.316333  , -0.464588  , -0.15674809,  0.20382392,  0.34551013,
         0.44472164,  0.17179596],
       [ 0.05437088,  0.09838217, -0.2624996 ,  0.46903235,  0.42123806,
         0.01350772, -0.42015588,  0.40093005, -0.21134704,  0.19722962,
        -0.44981372, -0.27371576],
       [-0.31923229, -0.16633162,  0.5103561 , -0.29615796,  0.08607394,
         0.33102566,  0.21985841,  0.17032665,  0.18801981, -0.0349198 ,
        -0.4259804 , -0.25559968],
       [-0.22957262, -0.3156608 ,  0.2148602 , -0.28025132,  0.46229672,
        -0.1572068 , -0.38639972, -0.09461975,  0.10479659,  0.14365792,
        -0.00124502,  0.06942022],
       [-0.38238838,  0.32005233,  0.18735188, -0.04645976, -0.3124533 ,
         0.47554505, -0.1611385 , -0.45845112, -0.23069924, -0.28417462,
         0.31739765,  0.01831472],
       [ 0.19509846, -0.484811  ,  0.1904515 , -0.3709216 ,  0.4360289 ,
        -0.3210299 ,  0.45100445, -0.03844136, -0.4209867 ,  0.16536742,
        -0.20201266,  0.46845734],
       [-0.32802078, -0.1501621 , -0.40377823, -0.25365692,  0.09802151,
         0.06379151,  0.0433659 , -0.40077895,  0.49973434, -0.03697291,
        -0.292679  ,  0.2708574 ],
       [-0.41355294,  0.22300708, -0.17605558, -0.18883386,  0.28338224,
         0.42083728, -0.23686707, -0.00124246,  0.03416395, -0.39703795,
         0.4442106 , -0.2925323 ],
       [ 0.14491868, -0.01195729, -0.21444899, -0.43849906, -0.246993  ,
         0.3506025 ,  0.31726664,  0.05678153, -0.36841673,  0.26719433,
        -0.01029736,  0.25612575],
       [-0.45549458,  0.12913549, -0.38748422, -0.25942105, -0.4032368 ,
        -0.40378174, -0.01426184, -0.41809082, -0.38306373, -0.16319403,
        -0.15302327, -0.03988352]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.21284112, -0.20489413,  0.30088866,  0.46018028, -0.39792687,
        -0.53479874, -0.09019738, -0.0701414 ],
       [ 0.39194506, -0.47712556,  0.0992189 ,  0.4338091 ,  0.07819265,
        -0.19066885, -0.19852668,  0.10210603],
       [-0.31017458, -0.39941555,  0.00787336, -0.4512258 , -0.08091551,
         0.04590392,  0.16830373, -0.42390144],
       [-0.28162   , -0.2752032 ,  0.4034583 ,  0.41829675,  0.08122081,
         0.15541041, -0.36789376,  0.14360929],
       [ 0.3214981 ,  0.36084896, -0.20745897, -0.2959411 , -0.17570788,
        -0.5437338 ,  0.16744512,  0.5100162 ],
       [-0.50186425,  0.06843686, -0.0849807 ,  0.00445527,  0.22434682,
         0.05659038, -0.37239394,  0.48366308],
       [-0.41879314,  0.52254546, -0.2847593 ,  0.40151906,  0.4084373 ,
        -0.14821663, -0.23830566, -0.4602191 ],
       [-0.15633422,  0.06198037, -0.37533906, -0.18493491,  0.51187885,
        -0.20404962,  0.18894774, -0.370707  ],
       [ 0.0830617 ,  0.4657073 , -0.35757113,  0.3046971 , -0.20186958,
        -0.35282528, -0.15103826, -0.5230997 ],
       [-0.24923736, -0.03161609, -0.2142328 ,  0.04609221, -0.366094  ,
         0.16441768, -0.25800225, -0.29032728],
       [-0.27861363, -0.5344647 ,  0.18258172, -0.220159  , -0.38627326,
         0.42921638,  0.22665334,  0.49308503],
       [-0.30938822,  0.41398978, -0.4994583 , -0.30113286,  0.38421154,
        -0.21531549, -0.21022195, -0.40895092]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.21074128],
       [-0.5133684 ],
       [-0.16357559],
       [ 0.545912  ],
       [ 0.30160844],
       [ 0.4413327 ],
       [ 0.78330684],
       [-0.5023767 ]], dtype=float32), array([0.], dtype=float32)]2021-05-22 12:00:52.102743: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-22 12:00:52.122337: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz


################################################################################
BEGIN MODEL DEFINITION

Epoch 1/20
  1/291 [..............................] - ETA: 1:32 - loss: 0.7241 - accuracy: 0.4000 67/291 [=====>........................] - ETA: 0s - loss: 0.6468 - accuracy: 0.6025  136/291 [=============>................] - ETA: 0s - loss: 0.6044 - accuracy: 0.6738198/291 [===================>..........] - ETA: 0s - loss: 0.5693 - accuracy: 0.7192280/291 [===========================>..] - ETA: 0s - loss: 0.5245 - accuracy: 0.7617291/291 [==============================] - 1s 727us/step - loss: 0.5183 - accuracy: 0.7667
Epoch 2/20
  1/291 [..............................] - ETA: 0s - loss: 0.1225 - accuracy: 1.0000 91/291 [========>.....................] - ETA: 0s - loss: 0.1071 - accuracy: 0.9802181/291 [=================>............] - ETA: 0s - loss: 0.0944 - accuracy: 0.9828271/291 [==========================>...] - ETA: 0s - loss: 0.0867 - accuracy: 0.9841291/291 [==============================] - 0s 559us/step - loss: 0.0853 - accuracy: 0.9842
Epoch 3/20
  1/291 [..............................] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000 88/291 [========>.....................] - ETA: 0s - loss: 0.0302 - accuracy: 0.9936178/291 [=================>............] - ETA: 0s - loss: 0.0326 - accuracy: 0.9926269/291 [==========================>...] - ETA: 0s - loss: 0.0340 - accuracy: 0.9924291/291 [==============================] - 0s 562us/step - loss: 0.0342 - accuracy: 0.9923
Epoch 4/20
  1/291 [..............................] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000 92/291 [========>.....................] - ETA: 0s - loss: 0.0280 - accuracy: 0.9925184/291 [=================>............] - ETA: 0s - loss: 0.0284 - accuracy: 0.9925265/291 [==========================>...] - ETA: 0s - loss: 0.0284 - accuracy: 0.9927291/291 [==============================] - 0s 618us/step - loss: 0.0286 - accuracy: 0.9927
Epoch 5/20
  1/291 [..............................] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 77/291 [======>.......................] - ETA: 0s - loss: 0.0207 - accuracy: 0.9933161/291 [===============>..............] - ETA: 0s - loss: 0.0219 - accuracy: 0.9939230/291 [======================>.......] - ETA: 0s - loss: 0.0229 - accuracy: 0.9943291/291 [==============================] - 0s 641us/step - loss: 0.0239 - accuracy: 0.9944
Epoch 6/20
  1/291 [..............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 92/291 [========>.....................] - ETA: 0s - loss: 0.0111 - accuracy: 0.9983181/291 [=================>............] - ETA: 0s - loss: 0.0187 - accuracy: 0.9973272/291 [===========================>..] - ETA: 0s - loss: 0.0210 - accuracy: 0.9970291/291 [==============================] - 0s 558us/step - loss: 0.0212 - accuracy: 0.9969
Epoch 7/20
  1/291 [..............................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000 91/291 [========>.....................] - ETA: 0s - loss: 0.0294 - accuracy: 0.9926182/291 [=================>............] - ETA: 0s - loss: 0.0269 - accuracy: 0.9939268/291 [==========================>...] - ETA: 0s - loss: 0.0255 - accuracy: 0.9945291/291 [==============================] - 0s 606us/step - loss: 0.0253 - accuracy: 0.9946
Epoch 8/20
  1/291 [..............................] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 90/291 [========>.....................] - ETA: 0s - loss: 0.0325 - accuracy: 0.9936180/291 [=================>............] - ETA: 0s - loss: 0.0287 - accuracy: 0.9945256/291 [=========================>....] - ETA: 0s - loss: 0.0266 - accuracy: 0.9951291/291 [==============================] - 0s 603us/step - loss: 0.0260 - accuracy: 0.9953
Epoch 9/20
  1/291 [..............................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 91/291 [========>.....................] - ETA: 0s - loss: 0.0149 - accuracy: 0.9979182/291 [=================>............] - ETA: 0s - loss: 0.0198 - accuracy: 0.9967272/291 [===========================>..] - ETA: 0s - loss: 0.0200 - accuracy: 0.9967291/291 [==============================] - 0s 557us/step - loss: 0.0200 - accuracy: 0.9967
Epoch 10/20
  1/291 [..............................] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 90/291 [========>.....................] - ETA: 0s - loss: 0.0150 - accuracy: 0.9979180/291 [=================>............] - ETA: 0s - loss: 0.0180 - accuracy: 0.9968269/291 [==========================>...] - ETA: 0s - loss: 0.0181 - accuracy: 0.9966291/291 [==============================] - 0s 563us/step - loss: 0.0181 - accuracy: 0.9966
Epoch 11/20
  1/291 [..............................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 59/291 [=====>........................] - ETA: 0s - loss: 0.0045 - accuracy: 0.9999145/291 [=============>................] - ETA: 0s - loss: 0.0138 - accuracy: 0.9981235/291 [=======================>......] - ETA: 0s - loss: 0.0163 - accuracy: 0.9975291/291 [==============================] - 0s 634us/step - loss: 0.0169 - accuracy: 0.9973
Epoch 12/20
  1/291 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 92/291 [========>.....................] - ETA: 0s - loss: 0.0089 - accuracy: 0.9980181/291 [=================>............] - ETA: 0s - loss: 0.0145 - accuracy: 0.9970250/291 [========================>.....] - ETA: 0s - loss: 0.0155 - accuracy: 0.9969291/291 [==============================] - 0s 602us/step - loss: 0.0159 - accuracy: 0.9970
Epoch 13/20
  1/291 [..............................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 90/291 [========>.....................] - ETA: 0s - loss: 0.0191 - accuracy: 0.9979180/291 [=================>............] - ETA: 0s - loss: 0.0180 - accuracy: 0.9973269/291 [==========================>...] - ETA: 0s - loss: 0.0172 - accuracy: 0.9973291/291 [==============================] - 0s 561us/step - loss: 0.0171 - accuracy: 0.9973
Epoch 14/20
  1/291 [..............................] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 90/291 [========>.....................] - ETA: 0s - loss: 0.0151 - accuracy: 0.9975155/291 [==============>...............] - ETA: 0s - loss: 0.0180 - accuracy: 0.9968244/291 [========================>.....] - ETA: 0s - loss: 0.0180 - accuracy: 0.9968291/291 [==============================] - 0s 613us/step - loss: 0.0176 - accuracy: 0.9970
Epoch 15/20
  1/291 [..............................] - ETA: 0s - loss: 9.5355e-04 - accuracy: 1.0000 90/291 [========>.....................] - ETA: 0s - loss: 0.0237 - accuracy: 0.9956    181/291 [=================>............] - ETA: 0s - loss: 0.0198 - accuracy: 0.9963272/291 [===========================>..] - ETA: 0s - loss: 0.0192 - accuracy: 0.9965291/291 [==============================] - 0s 559us/step - loss: 0.0189 - accuracy: 0.9965
Epoch 16/20
  1/291 [..............................] - ETA: 0s - loss: 0.0182 - accuracy: 1.0000 90/291 [========>.....................] - ETA: 0s - loss: 0.0277 - accuracy: 0.9965174/291 [================>.............] - ETA: 0s - loss: 0.0201 - accuracy: 0.9975251/291 [========================>.....] - ETA: 0s - loss: 0.0186 - accuracy: 0.9975291/291 [==============================] - 0s 601us/step - loss: 0.0181 - accuracy: 0.9975
Epoch 17/20
  1/291 [..............................] - ETA: 0s - loss: 0.2919 - accuracy: 0.9333 74/291 [======>.......................] - ETA: 0s - loss: 0.0299 - accuracy: 0.9944144/291 [=============>................] - ETA: 0s - loss: 0.0242 - accuracy: 0.9958235/291 [=======================>......] - ETA: 0s - loss: 0.0204 - accuracy: 0.9965291/291 [==============================] - 0s 638us/step - loss: 0.0192 - accuracy: 0.9967
Epoch 18/20
  1/291 [..............................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000 91/291 [========>.....................] - ETA: 0s - loss: 0.0047 - accuracy: 0.9999172/291 [================>.............] - ETA: 0s - loss: 0.0083 - accuracy: 0.9992260/291 [=========================>....] - ETA: 0s - loss: 0.0099 - accuracy: 0.9987291/291 [==============================] - 0s 581us/step - loss: 0.0104 - accuracy: 0.9985
Epoch 19/20
  1/291 [..............................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 92/291 [========>.....................] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985183/291 [=================>............] - ETA: 0s - loss: 0.0094 - accuracy: 0.9978273/291 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9976291/291 [==============================] - 0s 556us/step - loss: 0.0110 - accuracy: 0.9976
Epoch 20/20
  1/291 [..............................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 62/291 [=====>........................] - ETA: 0s - loss: 0.0102 - accuracy: 0.9981127/291 [============>.................] - ETA: 0s - loss: 0.0109 - accuracy: 0.9978215/291 [=====================>........] - ETA: 0s - loss: 0.0109 - accuracy: 0.9976291/291 [==============================] - 0s 669us/step - loss: 0.0110 - accuracy: 0.9975

################################################################################
EVALUATION

 1/68 [..............................] - ETA: 5s - loss: 0.0040 - accuracy: 1.000068/68 [==============================] - 0s 417us/step - loss: 0.0242 - accuracy: 0.9949
Loss Function Value:  0.02
Overall Accuracy   : 99.49%
--------------------------------------------------------------------------------
an own, very simple measure of performance:
(2145,) [5.8770180e-03 9.7946942e-01 2.2345781e-03 ... 5.0787032e-03 1.7021000e-03
 4.0760636e-04]
(2145,) [0 1 0 ... 0 0 0]
563.059205532074
